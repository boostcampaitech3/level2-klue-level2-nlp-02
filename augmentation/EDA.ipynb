{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3fe91c3-a12b-4b39-9b05-de8c0c6f8d4d",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd# EDA (Easy Data Augmentation)\n",
    "* SR (synonym replacement): 유의어로 바꾸기\n",
    "* RI (random insertion): 임의의 단어 삽입\n",
    "* RS (random swap): 특정 두 단어의 위치 바꾸기 - 이거 어카지\n",
    "* RD (random deletion): 임의의 단어 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca246f68-5625-472d-aed7-7220e896d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3965e336-488d-4d57-947a-b52e3f46749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc1317-552b-4f5c-9dc4-aca8f055ee47",
   "metadata": {},
   "source": [
    "KAIST에서 만든 유의어 데이터셋 wordnet 사용 <br>\n",
    "https://github.com/catSirup/KorEDA 에서 가져온 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcae56d5-a590-44a7-9b86-b72686db160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = {}\n",
    "with open(\"wordnet.pickle\", \"rb\") as f:\n",
    "\twordnet = pickle.load(f)\n",
    "\n",
    "\n",
    "# 한글만 남기고 나머지는 삭제\n",
    "def get_only_hangul(line):\n",
    "\tparseText= re.compile('/ ^[ㄱ-ㅎㅏ-ㅣ가-힣]*$/').sub('',line)\n",
    "\n",
    "\treturn parseText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed49acce-28d1-43f6-b2d4-496e6e065a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Synonym replacement\n",
    "# Replace n words in the sentence with synonyms from wordnet\n",
    "########################################################################\n",
    "def synonym_replacement(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\trandom_word_list = list(set([word for word in words]))\n",
    "\trandom.shuffle(random_word_list)\n",
    "\tnum_replaced = 0\n",
    "\tfor random_word in random_word_list:\n",
    "\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\tif len(synonyms) >= 1:\n",
    "\t\t\tsynonym = random.choice(list(synonyms))\n",
    "\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n",
    "\t\t\tnum_replaced += 1\n",
    "\t\tif num_replaced >= n:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tif len(new_words) != 0:\n",
    "\t\tsentence = ' '.join(new_words)\n",
    "\t\tnew_words = sentence.split(\" \")\n",
    "\n",
    "\telse:\n",
    "\t\tnew_words = \"\"\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "\n",
    "def get_synonyms(word):\n",
    "\tsynomyms = []\n",
    "\n",
    "\ttry:\n",
    "\t\tfor syn in wordnet[word]:\n",
    "\t\t\tfor s in syn:\n",
    "\t\t\t\tsynomyms.append(s)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "\treturn synomyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e3d00f-b9ce-4c8d-8f6e-244307ea11e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Random deletion\n",
    "# Randomly delete words from the sentence with probability p\n",
    "########################################################################\n",
    "def random_deletion(words, p):\n",
    "\tif len(words) == 1:\n",
    "\t\treturn words\n",
    "\n",
    "\tnew_words = []\n",
    "\tfor word in words:\n",
    "\t\tr = random.uniform(0, 1)\n",
    "\t\tif r > p:\n",
    "\t\t\tnew_words.append(word)\n",
    "\n",
    "\tif len(new_words) == 0:\n",
    "\t\trand_int = random.randint(0, len(words)-1)\n",
    "\t\treturn [words[rand_int]]\n",
    "\n",
    "\treturn new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f4387f-aebc-4a7b-9841-5f3dd00b2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Random swap\n",
    "# Randomly swap two words in the sentence n times\n",
    "########################################################################\n",
    "def random_swap(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tnew_words = swap_word(new_words)\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "def swap_word(new_words):\n",
    "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
    "\trandom_idx_2 = random_idx_1\n",
    "\tcounter = 0\n",
    "\n",
    "\twhile random_idx_2 == random_idx_1:\n",
    "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
    "\t\tcounter += 1\n",
    "\t\tif counter > 3:\n",
    "\t\t\treturn new_words\n",
    "\n",
    "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "\treturn new_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97e697b-ccb0-4e5c-960f-b85dad275f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Random insertion\n",
    "# Randomly insert n words into the sentence\n",
    "########################################################################\n",
    "def random_insertion(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tadd_word(new_words)\n",
    "\t\n",
    "\treturn new_words\n",
    "\n",
    "\n",
    "def add_word(new_words):\n",
    "\tsynonyms = []\n",
    "\tcounter = 0\n",
    "\twhile len(synonyms) < 1:\n",
    "\t\tif len(new_words) >= 1:\n",
    "\t\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n",
    "\t\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\t\tcounter += 1\n",
    "\t\telse:\n",
    "\t\t\trandom_word = \"\"\n",
    "\n",
    "\t\tif counter >= 10:\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\trandom_synonym = synonyms[0]\n",
    "\trandom_idx = random.randint(0, len(new_words)-1)\n",
    "\tnew_words.insert(random_idx, random_synonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9e04f99-e06d-41bb-a415-ae1680ba880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EDA(df, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=2):\n",
    "    eda_df = pd.DataFrame()\n",
    "        \n",
    "    for idx, sentence in enumerate(df['sentence']):\n",
    "        sentence = get_only_hangul(sentence)\n",
    "        words = sentence.split(' ')\n",
    "        words = [word for word in words if word != \"\"]\n",
    "        num_words = len(words)\n",
    "\n",
    "        augmented_sentences = []\n",
    "        num_new_per_technique = int(num_aug/4) + 1\n",
    "\n",
    "        n_sr = max(1, int(alpha_sr*num_words))\n",
    "        n_ri = max(1, int(alpha_ri*num_words))\n",
    "        n_rs = max(1, int(alpha_rs*num_words))\n",
    "\n",
    "        # # sr\n",
    "        # for _ in range(num_new_per_technique):\n",
    "        # \ta_words = synonym_replacement(words, n_sr)\n",
    "        # \ta_sent = ' '.join(a_words)\n",
    "        # \tif a_sent != sentence and a_sent not in augmented_sentences:\n",
    "        # \t\taugmented_sentences.append(a_sent)\n",
    "\n",
    "        #ri\n",
    "        # for _ in range(num_new_per_technique):\n",
    "        # \ta_words = random_insertion(words, n_ri)\n",
    "        # \ta_sent = ' '.join(a_words)\n",
    "        # \tif a_sent != sentence and a_sent not in augmented_sentences:\n",
    "        # \t\taugmented_sentences.append(a_sent)\n",
    "\n",
    "        # rs\n",
    "        for _ in range(num_new_per_technique):\n",
    "            a_words = random_swap(words, n_rs)\n",
    "            a_sent = ' '.join(a_words)\n",
    "            if a_sent != sentence and a_sent not in augmented_sentences:\n",
    "                augmented_sentences.append(a_sent)\n",
    "\n",
    "        #rd\n",
    "        for _ in range(num_new_per_technique):\n",
    "            a_words = random_deletion(words, p_rd)\n",
    "            a_sent = ' '.join(a_words)\n",
    "            if a_sent != sentence and a_sent not in augmented_sentences:\n",
    "                augmented_sentences.append(a_sent)\n",
    "\n",
    "        augmented_sentences = [get_only_hangul(sentence) for sentence in augmented_sentences]\n",
    "        random.shuffle(augmented_sentences)\n",
    "\n",
    "        if num_aug >= 1:\n",
    "            augmented_sentences = augmented_sentences[:num_aug]\n",
    "        else:\n",
    "            keep_prob = num_aug / len(augmented_sentences)\n",
    "            augmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
    "            \n",
    "        for s in augmented_sentences:\n",
    "            eda_df = eda_df.append(pd.DataFrame([[int(df[['id']].loc[idx]), s, '', '', df[['label']].loc[idx][0], df[['source']].loc[idx][0]]], columns=list(df.columns)))\n",
    "\n",
    "        # augmented_sentences.append(sentence)\n",
    "\n",
    "    return eda_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57e808ef-4ac7-4744-9de3-aee1aa3a15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_data(df,num):\n",
    "    under_data = pd.DataFrame()\n",
    "    for k,v in df['label'].value_counts().items():\n",
    "        if v < num:\n",
    "            under_key = df[df['label'] == k]\n",
    "            under_data = pd.concat([under_data, under_key])\n",
    "    under_data.reset_index(drop = True, inplace = True)\n",
    "    return under_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a2d802-03ca-47b2-b185-dcb59814c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity index 찾아서 생성된 데이터들을 저장한 df 생성\n",
    "def create_augmented_df(df, sb):\n",
    "    eda_df = pd.DataFrame()\n",
    "    unmatch = 0\n",
    "    for i in range(len(sb)):\n",
    "        se_dict = {}\n",
    "        oe_dict = {}\n",
    "\n",
    "        # subject entity, object entity\n",
    "        temp_df = data[data.id==sb.iloc[i]['id']]\n",
    "        se = eval(temp_df.iloc[0]['subject_entity'])['word']\n",
    "        oe = eval(temp_df.iloc[0]['object_entity'])['word']\n",
    "\n",
    "        # back_translation에서의 인덱스 위치 구하기\n",
    "        ## subject entity\n",
    "        se_start_idx = sb.loc[i]['sentence'].find(se)\n",
    "\n",
    "        if se_start_idx == -1:\n",
    "            # print(\"subject entity에 해당하는 단어가 없습니다.\")\n",
    "            unmatch += 1\n",
    "            continue\n",
    "\n",
    "        se_end_idx = se_start_idx + len(se)\n",
    "        if se != sb.iloc[i]['sentence'][se_start_idx:se_end_idx]:\n",
    "            print(\"오류: 인덱스가 잘못 설정됨.\")\n",
    "            break\n",
    "        else:\n",
    "            se_dict['word'] = se\n",
    "            se_dict['start_idx'] = se_start_idx\n",
    "            se_dict['end_idx'] = se_end_idx\n",
    "            se_dict['type'] = eval(df.loc[0]['subject_entity'])['type']\n",
    "        ## object entity\n",
    "        oe_start_idx = sb.loc[i]['sentence'].find(oe)\n",
    "        if oe_start_idx == -1:\n",
    "            # print(\"object entity에 해당하는 단어가 없습니다.\")\n",
    "            unmatch += 1\n",
    "            continue\n",
    "\n",
    "        oe_end_idx = oe_start_idx + len(oe)\n",
    "        if oe != sb.loc[i]['sentence'][oe_start_idx:oe_end_idx]:\n",
    "            print(\"오류: 인덱스가 잘못 설정됨.\")\n",
    "            # print(se, eda_list[i][se_start_idx:se_end_idx])\n",
    "            break\n",
    "        else:\n",
    "            oe_dict['word'] = oe\n",
    "            oe_dict['start_idx'] = oe_start_idx\n",
    "            oe_dict['end_idx'] = oe_end_idx\n",
    "            oe_dict['type'] = eval(df.loc[i%len(df)]['object_entity'])['type']\n",
    "\n",
    "        sb.loc[i, 'subject_entity'] = str(se_dict)\n",
    "        sb.loc[i, 'object_entity'] = str(oe_dict)\n",
    "        eda_df = eda_df.append(pd.DataFrame([[int(temp_df[['id']].iloc[0]), sb.iloc[i]['sentence'], str(se_dict), str(oe_dict), temp_df[['label']].iloc[0][0],temp_df[['source']].iloc[0][0]]], columns=list(temp_df.columns)))\n",
    "\n",
    "    return eda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdbd7fb6-071b-499a-9af7-8cf63b2bb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../dataset/train/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790b624-bda5-4e28-bb17-59b54809541d",
   "metadata": {},
   "source": [
    "중복데이터 없애는 거 어디갔냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b94ad0-2c04-4b5e-94cc-1a2a289ff2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_data = data[data['label'] != \"no_relation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c943337-ccd0-43fc-8d94-ef2bdb7314a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터 개수: 32470\n",
      "relation_data 개수: 22936\n"
     ]
    }
   ],
   "source": [
    "print(f\"총 데이터 개수: {data.shape[0]}\\nrelation_data 개수: {relation_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8d83416-8deb-4094-8461-d48938980307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org:top_members/employees              4284\n",
       "per:employee_of                        3573\n",
       "per:title                              2103\n",
       "org:member_of                          1866\n",
       "org:alternate_names                    1320\n",
       "per:origin                             1234\n",
       "org:place_of_headquarters              1195\n",
       "per:date_of_birth                      1130\n",
       "per:alternate_names                    1001\n",
       "per:spouse                              795\n",
       "per:colleagues                          534\n",
       "per:parents                             520\n",
       "org:founded                             450\n",
       "org:members                             420\n",
       "per:date_of_death                       418\n",
       "org:product                             380\n",
       "per:children                            304\n",
       "per:place_of_residence                  193\n",
       "per:other_family                        190\n",
       "per:place_of_birth                      166\n",
       "org:founded_by                          155\n",
       "per:product                             139\n",
       "per:siblings                            136\n",
       "org:political/religious_affiliation      98\n",
       "per:religion                             96\n",
       "per:schools_attended                     82\n",
       "org:dissolved                            66\n",
       "org:number_of_employees/members          48\n",
       "per:place_of_death                       40\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d37483-744a-4111-8212-82e0dadd19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "u1000_data = under_data(relation_data, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f2802bf-bca2-45d7-bab4-399c5fa511b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "per:spouse                             795\n",
       "per:colleagues                         534\n",
       "per:parents                            520\n",
       "org:founded                            450\n",
       "org:members                            420\n",
       "per:date_of_death                      418\n",
       "org:product                            380\n",
       "per:children                           304\n",
       "per:place_of_residence                 193\n",
       "per:other_family                       190\n",
       "per:place_of_birth                     166\n",
       "org:founded_by                         155\n",
       "per:product                            139\n",
       "per:siblings                           136\n",
       "org:political/religious_affiliation     98\n",
       "per:religion                            96\n",
       "per:schools_attended                    82\n",
       "org:dissolved                           66\n",
       "org:number_of_employees/members         48\n",
       "per:place_of_death                      40\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u1000_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d86658b2-83e4-48a7-a242-efca9c89d7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>첫 부인과의 사이에 장녀 박병숙을 두었고, 두 번째 부인은 경희대학교 교수를 지낸 ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:spouse</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>박흥식은 첫 부인과의 사이에 장녀 박병숙을 지냈다. 두 번째 부인은 경희대학교 교수...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:spouse</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>SK는 또 \"해당 방송에서 언급한 지난해 방송 또한 명백한 허위사실임을 알려드린다\"...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:spouse</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>언급한 또 \"해당 방송에서 SK는 지난해 12월5일 알려드린다\"며 가로세로연구소 방...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:spouse</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>채리나는 박용근을 생명의 은인으로 여기고 교제하다가 2016년 11월에 결혼하였다.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:spouse</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>29266</td>\n",
       "      <td>묵돌이 진나라가 된 209년에는 진시황이 사망한 직후였으며 이로 인해 선우가 큰 혼...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:place_of_death</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>30008</td>\n",
       "      <td>만네르헤임은 1951년 1월 27일(협정 세계시), 핀란드 시간으로는 1월 28일 ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:place_of_death</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>30008</td>\n",
       "      <td>만네르헤임은 1951년 1월 27일(협정 1월 핀란드 시간으로는 세계시), 28일 ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:place_of_death</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9501</th>\n",
       "      <td>30987</td>\n",
       "      <td>6월 2차 진주성 진주성이 함락되자 의병장인 김천일·고종후와 함께 촉석루에 올라 임...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:place_of_death</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9502</th>\n",
       "      <td>30987</td>\n",
       "      <td>1593년 6월 2차 진주성 전투에서 진주성이 함락되자 의병장인 김천일·고종후와 함...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>per:place_of_death</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9503 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           sentence subject_entity  \\\n",
       "0        22  첫 부인과의 사이에 장녀 박병숙을 두었고, 두 번째 부인은 경희대학교 교수를 지낸 ...                  \n",
       "1        22  박흥식은 첫 부인과의 사이에 장녀 박병숙을 지냈다. 두 번째 부인은 경희대학교 교수...                  \n",
       "2        25  SK는 또 \"해당 방송에서 언급한 지난해 방송 또한 명백한 허위사실임을 알려드린다\"...                  \n",
       "3        25  언급한 또 \"해당 방송에서 SK는 지난해 12월5일 알려드린다\"며 가로세로연구소 방...                  \n",
       "4        33     채리나는 박용근을 생명의 은인으로 여기고 교제하다가 2016년 11월에 결혼하였다.                  \n",
       "...     ...                                                ...            ...   \n",
       "9498  29266  묵돌이 진나라가 된 209년에는 진시황이 사망한 직후였으며 이로 인해 선우가 큰 혼...                  \n",
       "9499  30008  만네르헤임은 1951년 1월 27일(협정 세계시), 핀란드 시간으로는 1월 28일 ...                  \n",
       "9500  30008  만네르헤임은 1951년 1월 27일(협정 1월 핀란드 시간으로는 세계시), 28일 ...                  \n",
       "9501  30987  6월 2차 진주성 진주성이 함락되자 의병장인 김천일·고종후와 함께 촉석루에 올라 임...                  \n",
       "9502  30987  1593년 6월 2차 진주성 전투에서 진주성이 함락되자 의병장인 김천일·고종후와 함...                  \n",
       "\n",
       "     object_entity               label     source  \n",
       "0                           per:spouse  wikipedia  \n",
       "1                           per:spouse  wikipedia  \n",
       "2                           per:spouse   wikitree  \n",
       "3                           per:spouse   wikitree  \n",
       "4                           per:spouse  wikipedia  \n",
       "...            ...                 ...        ...  \n",
       "9498                per:place_of_death  wikipedia  \n",
       "9499                per:place_of_death  wikipedia  \n",
       "9500                per:place_of_death  wikipedia  \n",
       "9501                per:place_of_death   wikitree  \n",
       "9502                per:place_of_death   wikitree  \n",
       "\n",
       "[9503 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_df = EDA(u1000_data)\n",
    "ex_df.reset_index(drop = True, inplace = True)\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2588258-63ed-44f9-8f33-7e41b40d144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 문장 개수: 9503\n",
      "ex)\n",
      "   id                                           sentence subject_entity  \\\n",
      "0  22  첫 부인과의 사이에 장녀 박병숙을 두었고, 두 번째 부인은 경희대학교 교수를 지낸 ...                  \n",
      "1  22  박흥식은 첫 부인과의 사이에 장녀 박병숙을 지냈다. 두 번째 부인은 경희대학교 교수...                  \n",
      "2  25  SK는 또 \"해당 방송에서 언급한 지난해 방송 또한 명백한 허위사실임을 알려드린다\"...                  \n",
      "3  25  언급한 또 \"해당 방송에서 SK는 지난해 12월5일 알려드린다\"며 가로세로연구소 방...                  \n",
      "4  33     채리나는 박용근을 생명의 은인으로 여기고 교제하다가 2016년 11월에 결혼하였다.                  \n",
      "5  33  채리나는 이후 박용근을 생명의 은인으로 여기고 교제하다가 11월에 2016년 결혼하였다.                  \n",
      "6  40            배우 장신영(35) 품에 남편 강경준(36) 씨가 둘째를 씨와 안았다.                  \n",
      "\n",
      "  object_entity       label     source  \n",
      "0                per:spouse  wikipedia  \n",
      "1                per:spouse  wikipedia  \n",
      "2                per:spouse   wikitree  \n",
      "3                per:spouse   wikitree  \n",
      "4                per:spouse  wikipedia  \n",
      "5                per:spouse  wikipedia  \n",
      "6                per:spouse   wikitree  \n"
     ]
    }
   ],
   "source": [
    "print(f\"생성된 문장 개수: {len(ex_df)}\\nex)\\n{ex_df[:7]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb0b8d-06a4-4125-b439-150b30727390",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_augmented_df(u1000_data, aug_data)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45cbafb7-21c9-431c-b347-9f873bcc8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = pd.concat([data, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc629e2e-547a-468c-9d5a-d8ada3104824",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data.to_csv(\"./EDA(39680).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195755c-6da8-40d8-92e9-a9585c1d8aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b88a5422-330f-4936-b36b-4982c350c56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이듬해 1997년에는 부상에서 회복된 채로 시즌을 맞이했으나 7월 1일 요미우리전에서 내야 땅볼을 때린 뒤 1루수인 기요하라 가즈히로와 부딪혀 왼쪽 무릎에 타박상을 입었다.\n",
      "--------------------------------------------------\n",
      "이듬해 1997년에는 부상에서 회복된 채로 시즌을 맞이했으나 7월 1일 요미우리전에서 내야 땅볼을 때린 뒤 1루수인 기요하라 가즈히로와 부딪혀 무릎에 타박상을 입었다.\n",
      "\n",
      "\n",
      "무릎에 1997년에는 부상에서 회복된 채로 시즌을 맞이했으나 7월 1일 요미우리전에서 내야 땅볼을 때린 뒤 1루수인 타박상을 가즈히로와 부딪혀 왼쪽 이듬해 기요하라 입었다.\n",
      "\n",
      "\n",
      "이듬해 땅볼을 부상에서 회복된 채로 시즌을 맞이했으나 7월 무릎에 요미우리전에서 내야 1997년에는 때린 뒤 1루수인 기요하라 가즈히로와 부딪혀 왼쪽 1일 타박상을 입었다.\n",
      "\n",
      "\n",
      "이듬해 때린 부상에서 입었다. 채로 시즌을 맞이했으나 7월 1일 요미우리전에서 내야 땅볼을 1997년에는 뒤 1루수인 기요하라 가즈히로와 부딪혀 왼쪽 무릎에 타박상을 회복된\n",
      "\n",
      "\n",
      "이듬해 1997년에는 회복된 채로 시즌을 맞이했으나 7월 1일 요미우리전에서 내야 땅볼을 뒤 1루수인 기요하라 가즈히로와 부딪혀 왼쪽 무릎에 타박상을 입었다.\n",
      "\n",
      "\n",
      "이듬해 1997년에는 회복된 채로 시즌을 맞이했으나 7월 1일 요미우리전에서 내야 땅볼을 때린 뒤 1루수인 기요하라 가즈히로와 부딪혀 왼쪽 무릎에 타박상을 입었다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 걍 예시임\n",
    "print(ex_sent)\n",
    "print('-'*50)\n",
    "for a_s in ex_aug_sents:\n",
    "    if a_s != ex_sent:\n",
    "        print(a_s)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d92f9b-9f6f-4d84-aaf3-cb2388497a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc768903-3a98-4cc5-9af8-9d93b834494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "091a481a-4a7e-40c5-8693-54556a67951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4db53327-86e4-40bb-b171-df7e4ed1c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abc360-6f5d-4a4e-a6db-63714afc4e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
