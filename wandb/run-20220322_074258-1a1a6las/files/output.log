













  0%|▏                                                            | 105/40600 [00:27<2:58:52,  3.77it/s]












  0%|▎                                                            | 198/40600 [00:51<2:52:49,  3.90it/s]












  1%|▍                                                            | 291/40600 [01:15<2:52:41,  3.89it/s]














  1%|▌                                                            | 399/40600 [01:43<2:52:42,  3.88it/s]












  1%|▊                                                            | 500/40600 [02:09<3:28:53,  3.20it/s]***** Running Evaluation *****
  Num examples = 32470
  Batch size = 16
{'loss': 1.0238, 'learning_rate': 5e-05, 'epoch': 0.25}









































































 99%|██████████████████████████████████████████████████████████████▎| 2009/2030 [02:28<00:01, 13.58it/s]

Configuration saved in ./results/checkpoint-500/config.json
Model weights saved in ./results/checkpoint-500/pytorch_model.bin
Deleting older checkpoint [results/checkpoint-38500] due to args.save_total_limit












  1%|▉                                                            | 598/40600 [05:08<2:51:56,  3.88it/s]













  2%|█                                                            | 698/40600 [05:34<2:51:32,  3.88it/s]













  2%|█▏                                                           | 798/40600 [06:00<2:51:22,  3.87it/s]













  2%|█▎                                                           | 898/40600 [06:26<2:50:25,  3.88it/s]













  2%|█▌                                                           | 999/40600 [06:52<2:50:32,  3.87it/s]
  2%|█▍                                                          | 1000/40600 [06:52<3:28:34,  3.16it/s]***** Running Evaluation *****
  Num examples = 32470
  Batch size = 16










































































Configuration saved in ./results/checkpoint-1000/config.json
{'eval_loss': 0.6211423873901367, 'eval_micro f1 score': 81.08979872699123, 'eval_auprc': 69.0967805714586, 'eval_accuracy': 0.7937480751462889, 'eval_runtime': 149.6827, 'eval_samples_per_second': 216.926, 'eval_steps_per_second': 13.562, 'epoch': 0.49}
Model weights saved in ./results/checkpoint-1000/pytorch_model.bin
Deleting older checkpoint [results/checkpoint-39000] due to args.save_total_limit












  3%|█▌                                                          | 1097/40600 [09:50<2:50:13,  3.87it/s]







  3%|█▋                                                          | 1156/40600 [10:06<2:48:53,  3.89it/s]Traceback (most recent call last):
  File "train.py", line 151, in <module>
    wandb.init(project="test-project", entity="salt-bread")
  File "train.py", line 147, in main
    train()
  File "train.py", line 142, in train
    trainer.train()
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 1284, in train
    tr_loss += self.training_step(model, inputs)
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 1807, in training_step
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt